<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Loretta Cambron">
    <meta name="description" content="Loretta Cambron&#39;s personal website">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Why Is Explainability Important"/>
<meta name="twitter:description" content="Goeff Hinton recently tweeted [1] a question that got me thinking. At first blush, explainability sounds fantastic, and to be clear, I&rsquo;m pro-explainability. However, he poses an interesting thought - if a model, algorithm, or automated surgeon is more accurate than the prior human-run decision, does it matter if we can explain?
After an initial positive reaction (If I had cancer, I&rsquo;d choose the more accurate option and not question decisions made to get the cure), I&rsquo;m drawn to questioning what happens when things go wrong."/>

    <meta property="og:title" content="Why Is Explainability Important" />
<meta property="og:description" content="Goeff Hinton recently tweeted [1] a question that got me thinking. At first blush, explainability sounds fantastic, and to be clear, I&rsquo;m pro-explainability. However, he poses an interesting thought - if a model, algorithm, or automated surgeon is more accurate than the prior human-run decision, does it matter if we can explain?
After an initial positive reaction (If I had cancer, I&rsquo;d choose the more accurate option and not question decisions made to get the cure), I&rsquo;m drawn to questioning what happens when things go wrong." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lorettacambron.dev/posts/why-is-explainability-important/" />
<meta property="article:published_time" content="2020-02-23T18:24:46-06:00"/>
<meta property="article:modified_time" content="2020-02-23T18:24:46-06:00"/>


    
      <base href="https://lorettacambron.dev/posts/why-is-explainability-important/">
    
    <title>
  Why Is Explainability Important · lorettacambron
</title>

    
      <link rel="canonical" href="https://lorettacambron.dev/posts/why-is-explainability-important/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://lorettacambron.dev/css/coder.min.a4f332213a21ce8eb521670c614470c58923aaaf385e2a73982c31dd7642decb.css" integrity="sha256-pPMyITohzo61IWcMYURwxYkjqq84XipzmCwx3XZC3ss=" crossorigin="anonymous" media="screen" />
    

    

    

    
      <link rel="stylesheet" href="https://lorettacambron.dev/css/custom.css" />
    

    

    

    <link rel="icon" type="image/png" href="https://lorettacambron.dev/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://lorettacambron.dev/img/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.55.0" />
  </head>

  
  
  <body class="colorscheme-light">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://lorettacambron.dev/">
      lorettacambron
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://lorettacambron.dev/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://lorettacambron.dev/about/">About</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Why Is Explainability Important</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2020-02-23T18:24:46-06:00'>
                February 23, 2020
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              3-minute read
            </span>
          </div>
          
          
        </div>
      </header>

      <div>
        
        

<p>Goeff Hinton recently tweeted [<a href="https://twitter.com/geoffreyhinton/status/1230592238490615816?s=20">1</a>] a question that got me thinking. At first blush, explainability sounds fantastic, and to be clear, I&rsquo;m pro-explainability. However, he poses an interesting thought - if a model, algorithm, or automated surgeon is more accurate than the prior human-run decision, does it matter if we can explain?</p>

<p>After an initial positive reaction (If I had cancer, I&rsquo;d choose the more accurate option and not question decisions made to get the cure), I&rsquo;m drawn to questioning what happens when things go wrong. In this case, the robot surgeon has a 90% cure rate. What happens in the 10% of cases that are not cured? Or worse, what happens when the robot makes a mistake? Or when it turns out the robot was only trained on human males in clinical trials (this still happens <em>all the time</em> because there isn&rsquo;t regulation around equal participation of the sexes in clinical trials [<a href="https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419729071">2</a>].</p>

<p>When things go wrong, or when things are unexpected, <em>that</em> is when we need to be able to see what&rsquo;s going on in the model. That&rsquo;s when we need documentation on data used, data source, model architecture, and more [<a href="https://arxiv.org/pdf/1803.09010.pdf">3</a>, <a href="https://arxiv.org/pdf/1810.03993.pdf">4</a>].</p>

<p>There are broader questions here too regarding legal implications [<a href="https://arxiv.org/abs/1912.00761">5</a>]. If a robot-surgeon makes a mistake, or robot-doctor prescribes a harmful treatment plan, how does a malpractice trial go? Are engineers responsible for medical ramifications? In an early version of Tesla&rsquo;s automated driving software, researchers were able to trick computer vision models into speeding (35 mph was read as 85 mph with a slight change to the &ldquo;3&rdquo; on the sign)[<a href="https://www.technologyreview.com/s/615244/hackers-can-trick-a-tesla-into-accelerating-by-50-miles-per-hour/">6</a>]. In the same way, if a driver is pulled over, in a car they were told they need not drive, who gets a speeding ticket? Is Tesla liable for &ldquo;bad driving&rdquo; which stems from their software?</p>

<p>These are complicated issues, and there are as many opportunities to harm as there are to help. It&rsquo;s clear to me that at the very least, we need to keep circulating this topic of conversation. As technology is more and more interwoven into our lives, we should look to interdisciplinary policy and regulation to hold companies accountable and keep consumers informed.</p>

<p>Geoff&rsquo;s question is vague, and I made a few assumptions to hash out my thoughts. What are some angles to add to this conversation? How do you respond to Geoff&rsquo;s question?</p>

<h4 id="further-reading-and-sources">Further reading and sources:</h4>

<ol>
<li>Geoff Hinton&rsquo;s tweet: <a href="https://twitter.com/geoffreyhinton/status/1230592238490615816?s=20">https://twitter.com/geoffreyhinton/status/1230592238490615816?s=20</a></li>
<li>Recommend reading Caroline Criado-Parez&rsquo;s thoroughly researched book: <a href="https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419729071">https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419729071</a></li>
<li>Datasheets for datasets, the way I wish all datasets were documented: <a href="https://arxiv.org/pdf/1803.09010.pdf">https://arxiv.org/pdf/1803.09010.pdf</a></li>
<li>Model cards for model reporting (this paper and the previous were written by some of my favorite thought leaders, definitely them out): <a href="https://arxiv.org/pdf/1810.03993.pdf">https://arxiv.org/pdf/1810.03993.pdf</a></li>
<li>Neat paper about how the fields of law and machine learning need to work together (and how it&rsquo;s gone wrong sometimes): <a href="https://arxiv.org/abs/1912.00761">https://arxiv.org/abs/1912.00761</a></li>
<li>Article about researchers testing (and &ldquo;tricking&rdquo;) Tesla&rsquo;s software: <a href="https://www.technologyreview.com/s/615244/hackers-can-trick-a-tesla-into-accelerating-by-50-miles-per-hour/">https://www.technologyreview.com/s/615244/hackers-can-trick-a-tesla-into-accelerating-by-50-miles-per-hour/</a></li>
</ol>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yourdiscussshortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js" id="MathJax-script"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'], ['\\(', '\\)']
        ],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
      <p>Welcome! Have a look around.</p>
    
    
      
        © 2020
      
       Loretta Cambron 
    
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    

    

  </body>

</html>
